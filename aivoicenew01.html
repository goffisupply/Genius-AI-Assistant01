<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Assistant</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.18.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/speech-commands@0.5.4/dist/speech-commands.min.js"></script>
    
    <style>
        body {
            margin: 0;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
            -webkit-font-smoothing: antialiased;
            -moz-osx-font-smoothing: grayscale;
            background-color: #f5f7fb;
            color: #333;
        }

        .app {
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }

        header {
            text-align: center;
            margin-bottom: 30px;
        }

        h1 {
            color: #2c3e50;
        }

        main {
            background-color: white;
            border-radius: 10px;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
            padding: 20px;
        }

        .status-container {
            display: flex;
            align-items: center;
            margin-bottom: 20px;
            padding: 15px;
            background-color: #f9f9f9;
            border-radius: 8px;
        }

        .status-indicator {
            width: 16px;
            height: 16px;
            border-radius: 50%;
            background-color: #ccc;
            margin-right: 10px;
        }

        .status-indicator.active {
            background-color: #4CAF50;
            box-shadow: 0 0 8px #4CAF50;
            animation: pulse 2s infinite;
        }

        @keyframes pulse {
            0% {
                box-shadow: 0 0 0 0 rgba(76, 175, 80, 0.7);
            }
            70% {
                box-shadow: 0 0 0 10px rgba(76, 175, 80, 0);
            }
            100% {
                box-shadow: 0 0 0 0 rgba(76, 175, 80, 0);
            }
        }

        .status-text {
            font-size: 16px;
            font-weight: 500;
        }

        .toggle-button {
            display: block;
            width: 100%;
            padding: 15px;
            border: none;
            border-radius: 8px;
            background-color: #3498db;
            color: white;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: background-color 0.3s;
            margin-bottom: 20px;
        }

        .toggle-button:hover {
            background-color: #2980b9;
        }

        .toggle-button.running {
            background-color: #e74c3c;
        }

        .toggle-button.running:hover {
            background-color: #c0392b;
        }

        .conversation {
            margin-bottom: 20px;
            padding: 15px;
            background-color: #f9f9f9;
            border-radius: 8px;
            min-height: 100px;
        }

        .question-container, .response-container {
            margin-bottom: 15px;
        }

        .question-container h3, .response-container h3 {
            margin-bottom: 5px;
            color: #2c3e50;
            font-size: 16px;
        }

        .logs {
            margin-top: 20px;
        }

        .logs h3 {
            margin-bottom: 10px;
            color: #2c3e50;
            font-size: 16px;
        }

        .log-container {
            max-height: 200px;
            overflow-y: auto;
            padding: 10px;
            background-color: #f5f5f5;
            border-radius: 5px;
            border: 1px solid #ddd;
        }

        .log-entry {
            padding: 5px 0;
            border-bottom: 1px solid #eee;
            font-family: monospace;
            font-size: 14px;
        }

        .log-entry:last-child {
            border-bottom: none;
        }

        footer {
            margin-top: 20px;
            text-align: center;
            color: #7f8c8d;
            font-size: 14px;
        }

        .permission-button {
            display: block;
            margin: 20px auto;
            padding: 10px 20px;
            background-color: #2ecc71;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-size: 16px;
        }

        .permission-button:hover {
            background-color: #27ae60;
        }

        .hidden {
            display: none;
        }
        
        .audio-device-selector {
            margin: 15px 0;
            padding: 10px;
            background-color: #f0f4f8;
            border-radius: 8px;
        }
        
        .audio-device-selector select {
            width: 100%;
            padding: 8px;
            margin-top: 8px;
            border-radius: 4px;
            border: 1px solid #ddd;
        }
    </style>
</head>
<body>
    <div class="app">
        <header>
            <h1>Voice Assistant</h1>
        </header>
        
        <main>
            <!-- Initial mic permission section -->
            <div id="permissionSection">
                <p>This app requires microphone access to function. Please click below to grant permission:</p>
                <button id="permissionButton" class="permission-button">Enable Microphone</button>
            </div>

            <!-- Audio device selection (will be shown after permission) -->
            <div id="audioDeviceSection" class="audio-device-selector hidden">
                <p>Select your preferred audio input device:</p>
                <select id="audioInputSelect"></select>
                <button id="confirmAudioDevice" class="permission-button">Use Selected Device</button>
            </div>

            <!-- Main app UI (hidden initially) -->
            <div id="appUI" class="hidden">
                <div class="status-container">
                    <div id="statusIndicator" class="status-indicator"></div>
                    <div id="statusText" class="status-text">Idle</div>
                </div>
                
                <button id="toggleButton" class="toggle-button">Start Assistant</button>
                
                <div class="conversation">
                    <div id="questionContainer" class="question-container" style="display: none;">
                        <h3>Your Question:</h3>
                        <p id="questionText"></p>
                    </div>
                    
                    <div id="responseContainer" class="response-container" style="display: none;">
                        <h3>Assistant's Response:</h3>
                        <p id="responseText"></p>
                    </div>
                </div>
                
                <div class="logs">
                    <h3>Activity Log:</h3>
                    <div id="logContainer" class="log-container"></div>
                </div>
            </div>
        </main>
        
        <footer>
            <p>This app will continue running in a background tab when minimized.</p>
        </footer>
    </div>
    
    <script>
        // Global variables
        let isRunning = false;
        let recognizer = null;
        let recognition = null;
        let audioContext = null;
        let speechSynthesis = window.speechSynthesis;
        let apiKey = "AIzaSyAS3hXY8q6HypRoIb9cN3WQbsFyBDYUNYk"; // Gemini API key from your Python code
        let wakeLock = null; // For keeping the app active in background
        let selectedAudioDeviceId = null;
        let audioStream = null;

        // DOM elements
        const permissionSection = document.getElementById('permissionSection');
        const permissionButton = document.getElementById('permissionButton');
        const audioDeviceSection = document.getElementById('audioDeviceSection');
        const audioInputSelect = document.getElementById('audioInputSelect');
        const confirmAudioDevice = document.getElementById('confirmAudioDevice');
        const appUI = document.getElementById('appUI');
        const statusIndicator = document.getElementById('statusIndicator');
        const statusText = document.getElementById('statusText');
        const toggleButton = document.getElementById('toggleButton');
        const questionContainer = document.getElementById('questionContainer');
        const questionText = document.getElementById('questionText');
        const responseContainer = document.getElementById('responseContainer');
        const responseText = document.getElementById('responseText');
        const logContainer = document.getElementById('logContainer');

        // Check if running as a PWA/standalone app
        const isStandalone = window.matchMedia('(display-mode: standalone)').matches || 
                             window.navigator.standalone || 
                             document.referrer.includes('android-app://');

        // Initialize device detection
        document.addEventListener('DOMContentLoaded', function() {
            addLog("App initialized. Ready to start voice assistant.");
            
            // Check if we're running in a Cordova/Capacitor environment
            if (window.cordova) {
                addLog("Running in Cordova environment");
                document.addEventListener('deviceready', onDeviceReady, false);
            } else {
                addLog("Running in browser environment");
            }
        });

        // Cordova/Capacitor device ready handler
        function onDeviceReady() {
            addLog("Device ready event fired");
            
            // Request permissions on Android programmatically
            if (window.cordova.platformId === 'android') {
                requestAndroidPermissions();
            }
        }

        // Request Android permissions programmatically
        function requestAndroidPermissions() {
            if (window.cordova && window.cordova.plugins && window.cordova.plugins.permissions) {
                const permissions = [
                    window.cordova.plugins.permissions.RECORD_AUDIO,
                    window.cordova.plugins.permissions.MODIFY_AUDIO_SETTINGS
                ];
                
                window.cordova.plugins.permissions.requestPermissions(permissions, permissionSuccess, permissionError);
            }
        }

        function permissionSuccess() {
            addLog("Android permissions granted programmatically");
            // Proceed to audio device setup
            permissionGranted();
        }

        function permissionError() {
            addLog("Failed to get Android permissions programmatically");
            // Fall back to manual permission request
        }

        // Request microphone permission
        permissionButton.addEventListener('click', async () => {
            try {
                // Request microphone permission with specific constraints for better compatibility
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    } 
                });
                
                // Keep the stream active to maintain permission
                audioStream = stream;
                
                // Proceed with permission granted flow
                permissionGranted();
            } catch (error) {
                addLog(`Error: ${error.message}`);
                alert("Microphone access is required for this app to function.");
            }
        });

        // After permission is granted
        async function permissionGranted() {
            try {
                // Hide permission section
                permissionSection.classList.add('hidden');
                
                // Initialize audio context
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                
                // Enumerate audio devices
                await enumerateAudioDevices();
                
                // Show audio device selection
                audioDeviceSection.classList.remove('hidden');
                
                addLog("Microphone access granted");
            } catch (error) {
                addLog(`Error setting up audio: ${error.message}`);
                
                // If device enumeration fails, go directly to main UI
                audioDeviceSection.classList.add('hidden');
                appUI.classList.remove('hidden');
            }
        }

        // Enumerate available audio input devices
        async function enumerateAudioDevices() {
            try {
                const devices = await navigator.mediaDevices.enumerateDevices();
                const audioInputs = devices.filter(device => device.kind === 'audioinput');
                
                // Clear the select
                audioInputSelect.innerHTML = '';
                
                // Add each device to the select
                audioInputs.forEach(device => {
                    const option = document.createElement('option');
                    option.value = device.deviceId;
                    option.text = device.label || `Microphone ${audioInputSelect.length + 1}`;
                    
                    // Add specific text for Bluetooth devices to make them easier to identify
                    if (option.text.toLowerCase().includes('bluetooth') || 
                        option.text.toLowerCase().includes('wireless') ||
                        option.text.toLowerCase().includes('headset')) {
                        option.text += ' (Bluetooth/Wireless)';
                    }
                    
                    audioInputSelect.appendChild(option);
                });
                
                addLog(`Found ${audioInputs.length} audio input devices`);
            } catch (error) {
                addLog(`Error enumerating audio devices: ${error.message}`);
            }
        }

        // Confirm audio device selection
        confirmAudioDevice.addEventListener('click', async () => {
            selectedAudioDeviceId = audioInputSelect.value;
            addLog(`Selected audio device: ${audioInputSelect.options[audioInputSelect.selectedIndex].text}`);
            
            // Stop the initial stream
            if (audioStream) {
                audioStream.getTracks().forEach(track => track.stop());
            }
            
            // Create a new stream with the selected device
            try {
                audioStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        deviceId: { exact: selectedAudioDeviceId },
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });
                
                addLog("Successfully connected to selected audio device");
            } catch (error) {
                addLog(`Error connecting to selected device: ${error.message}`);
            }
            
            // Hide audio device section and show main UI
            audioDeviceSection.classList.add('hidden');
            appUI.classList.remove('hidden');
        });

        // Toggle voice assistant on/off
        toggleButton.addEventListener('click', () => {
            if (isRunning) {
                stopAssistant();
            } else {
                startAssistant();
            }
        });

        // Start the voice assistant
        async function startAssistant() {
            try {
                isRunning = true;
                toggleButton.textContent = "Stop Assistant";
                toggleButton.classList.add("running");
                statusIndicator.classList.add("active");
                updateStatus("Initializing...");
                addLog("Voice assistant starting...");
                
                // Request wake lock to keep device active
                await requestWakeLock();

                // Initialize the keyword spotting
                await initKeywordSpotting();
                
                // Set up speech recognition
                setupSpeechRecognition();
                
                // Initialize Web Speech API for speech synthesis
                if (!speechSynthesis) {
                    addLog("Warning: Speech synthesis not supported in this browser");
                }
                
                // Start foreground service if in Cordova environment
                if (window.cordova && window.cordova.plugins && window.cordova.plugins.foregroundService) {
                    window.cordova.plugins.foregroundService.start('Voice Assistant', 
                        'Voice Assistant is running', 'icon');
                    addLog("Started foreground service");
                }
                
                updateStatus("Listening for 'Genius'...");
            } catch (error) {
                addLog(`Error starting assistant: ${error.message}`);
                stopAssistant();
            }
        }

        // Stop the voice assistant
        function stopAssistant() {
            isRunning = false;
            toggleButton.textContent = "Start Assistant";
            toggleButton.classList.remove("running");
            statusIndicator.classList.remove("active");
            updateStatus("Idle");
            addLog("Voice assistant stopped");

            // Stop keyword recognition
            if (recognizer) {
                recognizer.stopListening();
            }
            
            // Stop speech recognition
            if (recognition) {
                recognition.stop();
            }
            
            // Stop any ongoing speech
            if (speechSynthesis) {
                speechSynthesis.cancel();
            }
            
            // Release wake lock
            releaseWakeLock();
            
            // Stop foreground service if in Cordova environment
            if (window.cordova && window.cordova.plugins && window.cordova.plugins.foregroundService) {
                window.cordova.plugins.foregroundService.stop();
                addLog("Stopped foreground service");
            }
        }

        // Request wake lock to prevent device from sleeping
        async function requestWakeLock() {
            try {
                if ('wakeLock' in navigator) {
                    wakeLock = await navigator.wakeLock.request('screen');
                    addLog("Wake lock acquired - device will stay awake");
                    
                    wakeLock.addEventListener('release', () => {
                        addLog("Wake lock released");
                    });
                } else {
                    addLog("Wake Lock API not supported on this device");
                    
                    // Alternative approach for older devices
                    if (window.cordova && window.cordova.plugins && window.cordova.plugins.backgroundMode) {
                        window.cordova.plugins.backgroundMode.enable();
                        addLog("Background mode enabled via Cordova");
                    }
                }
            } catch (error) {
                addLog(`Error acquiring wake lock: ${error.message}`);
            }
        }

        // Release wake lock
        function releaseWakeLock() {
            if (wakeLock) {
                wakeLock.release()
                    .then(() => {
                        wakeLock = null;
                        addLog("Wake lock released manually");
                    })
                    .catch(error => {
                        addLog(`Error releasing wake lock: ${error.message}`);
                    });
            }
            
            // Disable background mode if using Cordova
            if (window.cordova && window.cordova.plugins && window.cordova.plugins.backgroundMode) {
                window.cordova.plugins.backgroundMode.disable();
                addLog("Background mode disabled");
            }
        }

        // Initialize keyword spotting using TensorFlow.js
        async function initKeywordSpotting() {
            try {
                // Load the speech commands model
                recognizer = speechCommands.create('BROWSER_FFT');
                await recognizer.ensureModelLoaded();
                addLog("Speech commands model loaded");
                
                // Start listening for keywords
                // We'll use "yes" as a proxy for "Genius" since it's included in the default model
                recognizer.listen(result => {
                    if (!isRunning) return;
                    
                    const scores = Array.from(result.scores);
                    const maxScore = Math.max(...scores);
                    const maxScoreIndex = scores.indexOf(maxScore);
                    const wordLabels = recognizer.wordLabels();
                    const detectedWord = wordLabels[maxScoreIndex];
                    
                    // Check if "yes" was detected (as a proxy for "Genius")
                    if (detectedWord === 'yes' && maxScore > 0.8) {
                        handleKeywordDetected();
                    }
                }, {
                    includeSpectrogram: true,
                    probabilityThreshold: 0.8,
                    // Specify the audio device to use if one is selected
                    audioTrackConstraints: selectedAudioDeviceId ? {
                        deviceId: { exact: selectedAudioDeviceId }
                    } : undefined
                });
            } catch (error) {
                addLog(`Error initializing keyword spotting: ${error.message}`);
                throw error;
            }
        }

        // Set up the Web Speech API for speech recognition
        function setupSpeechRecognition() {
            // Check if browser supports speech recognition
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) {
                addLog("Error: Speech recognition not supported in this browser");
                return;
            }
            
            // Create recognition object
            recognition = new SpeechRecognition();
            recognition.continuous = false;
            recognition.interimResults = false;
            recognition.lang = 'en-US';
            
            // Try to set audio source to selected device if available
            // Note: This is not officially supported by the Web Speech API spec
            // but some browsers may support it through non-standard extensions
            try {
                if (selectedAudioDeviceId && recognition.audioSource) {
                    recognition.audioSource = selectedAudioDeviceId;
                    addLog("Set speech recognition to use selected audio device");
                }
            } catch (e) {
                addLog("Could not set audio source for speech recognition");
            }
            
            // Set up result handler
            recognition.onresult = (event) => {
                const last = event.results.length - 1;
                const text = event.results[last][0].transcript.trim();
                
                questionText.textContent = text;
                questionContainer.style.display = 'block';
                addLog(`Question: ${text}`);
                
                // Generate response
                generateResponse(text);
            };
            
            // Set up error handler
            recognition.onerror = (event) => {
                addLog(`Speech recognition error: ${event.error}`);
                updateStatus("Listening for 'Genius'...");
            };
        }

        // Handle keyword detection ("Genius")
        function handleKeywordDetected() {
            addLog("Keyword 'Genius' detected!");
            updateStatus("Say your question...");
            playBeep(1, 1000, 0.5, 1800);
            
            // Pause keyword spotting temporarily
            if (recognizer) {
                recognizer.stopListening();
            }
            
            // Start speech recognition after a short delay
            setTimeout(() => {
                if (recognition && isRunning) {
                    recognition.start();
                }
            }, 1000);
        }

        // Generate response from Gemini API
        async function generateResponse(prompt) {
            try {
                updateStatus("Generating response...");
                addLog("Contacting Gemini API...");
                
                // API endpoint for Gemini
                const url = `https://generativelanguage.googleapis.com/v1/models/gemini-1.5-flash:generateContent?key=${apiKey}`;
                
                // Prepare request body
                const requestBody = {
                    contents: [
                        {
                            parts: [
                                { text: prompt }
                            ]
                        }
                    ],
                    generationConfig: {
                        temperature: 0.7,
                        maxOutputTokens: 800
                    }
                };
                
                // Make API request
                const response = await fetch(url, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify(requestBody)
                });
                
                if (!response.ok) {
                    throw new Error(`API error: ${response.status}`);
                }
                
                const data = await response.json();
                
                // Extract the response text
                let responseString = "";
                if (data.candidates && data.candidates[0] && data.candidates[0].content && data.candidates[0].content.parts) {
                    responseString = data.candidates[0].content.parts[0].text;
                } else {
                    throw new Error("Invalid response format from API");
                }
                
                // Display response
                responseText.textContent = responseString;
                responseContainer.style.display = 'block';
                addLog(`Response received: ${responseString.substring(0, 50)}...`);
                
                // Speak the response
                speakResponse(responseString);
            } catch (error) {
                addLog(`Error generating response: ${error.message}`);
                
                // Fallback response if API fails
                const fallbackResponse = "I'm sorry, I couldn't process that request due to a connection issue or API error.";
                responseText.textContent = fallbackResponse;
                responseContainer.style.display = 'block';
                speakResponse(fallbackResponse);
            }
        }

        // Speak response using Web Speech API
        function speakResponse(text) {
            updateStatus("Speaking response...");
            
            // Check if speech synthesis is available
            if (!speechSynthesis) {
                addLog("Speech synthesis not available");
                resetAfterResponse();
                return;
            }
            
            // Create speech utterance
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.rate = 1.0; // Normal speed
            
            // Route audio through Bluetooth if available
            // Note: This is handled by the OS, but we can try to set audio constraints
            // Try to use Bluetooth audio output if available
            try {
                // This is experimental and not supported in all browsers
                if (window.cordova && window.cordova.plugins && window.cordova.plugins.audioRouting) {
                    window.cordova.plugins.audioRouting.setPreferredOutputAudio('bluetooth');
                }
            } catch (e) {
                addLog("Could not explicitly set Bluetooth audio output");
            }
            
            // Set up end event
            utterance.onend = () => {
                resetAfterResponse();
            };
            
            // Set up error event
            utterance.onerror = (event) => {
                addLog(`Speech synthesis error: ${event.error}`);
                resetAfterResponse();
            };
            
            // Speak the text
            speechSynthesis.speak(utterance);
        }

        // Reset after response is complete
        function resetAfterResponse() {
            if (!isRunning) return;
            
            updateStatus("Listening for 'Genius'...");
            
            // Restart keyword spotting
            if (recognizer) {
                recognizer.listen(result => {
                    if (!isRunning) return;
                    
                    const scores = Array.from(result.scores);
                    const maxScore = Math.max(...scores);
                    const maxScoreIndex = scores.indexOf(maxScore);
                    const wordLabels = recognizer.wordLabels();
                    const detectedWord = wordLabels[maxScoreIndex];
                    
                    if (detectedWord === 'yes' && maxScore > 0.8) {
                        handleKey
